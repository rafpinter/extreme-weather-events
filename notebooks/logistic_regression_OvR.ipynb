{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from logistic_regression import LogisticRegression, LogisticRegressionOvR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = \"../data/train.csv\"\n",
    "raw_test_data = \"../data/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44760, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc = Preprocess()\n",
    "raw_data = preproc.load_data(raw_train_data)\n",
    "train_df, train_data = preproc.preprocess_data(raw_data)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.785947\n",
       "2    0.173280\n",
       "1    0.040773\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = preproc.train_valid_split(\n",
    "    train_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaelapinter/Library/Mobile Documents/com~apple~CloudDocs/1.UdeM/github-projects/extreme-weather-events-ift6380/notebooks/logistic_regression.py:106: RuntimeWarning: overflow encountered in exp\n",
      "  def fit(self, X, y):\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegressionOvR(lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    0     0 11629]\n",
      " [    0     0   578]\n",
      " [    0     0  2564]] \n",
      "\n",
      "Accuracy:\n",
      "0.1736 \n",
      "\n",
      "Precision:\n",
      "0.0579 \n",
      "\n",
      "Recall:\n",
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tá uma porcaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    0     0 11629]\n",
      " [    0     0   578]\n",
      " [    0     0  2564]] \n",
      "\n",
      "Accuracy:\n",
      "0.1736 \n",
      "\n",
      "Precision:\n",
      "0.0579 \n",
      "\n",
      "Recall:\n",
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegressionOvR(lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ainda tá uma bela duma bosta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.normalize_data(X_train)\n",
    "X_valid = preproc.normalize_data(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    0     0 11629]\n",
      " [    0     0   578]\n",
      " [    0     0  2564]] \n",
      "\n",
      "Accuracy:\n",
      "0.1736 \n",
      "\n",
      "Precision:\n",
      "0.0579 \n",
      "\n",
      "Recall:\n",
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegressionOvR(learning_rate=0.02, num_iterations=1000, lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaelapinter/Library/Mobile Documents/com~apple~CloudDocs/1.UdeM/github-projects/extreme-weather-events-ift6380/notebooks/logistic_regression.py:125: RuntimeWarning: overflow encountered in exp\n",
      "  # Update weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[11629     0     0]\n",
      " [  578     0     0]\n",
      " [ 2564     0     0]] \n",
      "\n",
      "Accuracy:\n",
      "0.7873 \n",
      "\n",
      "Precision:\n",
      "0.2624 \n",
      "\n",
      "Recall:\n",
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegressionOvR(learning_rate=0.02, num_iterations=1000, lambda_reg=0.5)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentando menos colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"lat\", \"lon\", \"PS\", \"Z1000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sel = raw_data[cols]\n",
    "\n",
    "train_df, train_data = preproc.preprocess_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = preproc.train_valid_split(\n",
    "    train_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.normalize_data(X_train)\n",
    "X_valid = preproc.normalize_data(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegressionOvR(learning_rate=0.01, num_iterations=200, lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentando um modelo só"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = preproc.train_valid_split(\n",
    "    train_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.normalize_data(X_train)\n",
    "X_valid = preproc.normalize_data(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[    0  2564]\n",
      " [    0 12207]] \n",
      "\n",
      "Accuracy:\n",
      "0.8264 \n",
      "\n",
      "Precision:\n",
      "0.4132 \n",
      "\n",
      "Recall:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegression(learning_rate=0.1, num_iterations=100, lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid, augment=True)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tentando undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0 = train_df[train_df['Label'] == 0].sample(n=7756)\n",
    "train_2 = train_df[train_df['Label'] == 2].copy()\n",
    "\n",
    "train_set_balaced = pd.concat([train_0, train_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_balaced = train_set_balaced.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preproc.normalize_data(X_train)\n",
    "X_valid = preproc.normalize_data(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = preproc.train_valid_split(\n",
    "    train_set_balaced, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0 2560    0]\n",
      " [   0    0    0]\n",
      " [   0 2559    0]] \n",
      "\n",
      "Accuracy:\n",
      "0.0 \n",
      "\n",
      "Precision:\n",
      "0.0 \n",
      "\n",
      "Recall:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Creating model instance\n",
    "lr = LogisticRegression(learning_rate=0.01, num_iterations=200, lambda_reg=0.1)\n",
    "\n",
    "# Fitting model\n",
    "lr.fit(X=X_train, y=y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = lr.predict(X=X_valid, augment=True)\n",
    "\n",
    "# Print results\n",
    "lr.get_metrics(y_true=y_valid, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropando mais colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dc1-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
